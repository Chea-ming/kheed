{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be06cd51",
   "metadata": {},
   "source": [
    "# Imports and Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d37cbf2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/Public/kheed/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "CUDA Device: NVIDIA GeForce RTX 4070 Ti SUPER\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, default_collate\n",
    "from transformers import MBartConfig, MBartModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from seqeval.metrics import precision_score, recall_score, f1_score\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from khmernltk import word_tokenize\n",
    "\n",
    "# Suppress tokenizer parallelism warning\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Set seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# Verify CUDA availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if device.type == \"cuda\":\n",
    "    print(f\"CUDA Device: {torch.cuda.get_device_name(0)}\")\n",
    "    torch.cuda.empty_cache()  # Clear CUDA cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1197cd",
   "metadata": {},
   "source": [
    "# Custom Collate Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7eea9558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch):\n",
    "    batch = [{k: v for k, v in sample.items() if k in ['input_ids', 'attention_mask', 'labels']} for sample in batch]\n",
    "    return default_collate(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbb9f0d",
   "metadata": {},
   "source": [
    "# Data Loading Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bedc19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_files(input_dir, input_files):\n",
    "    all_tokens = []\n",
    "    all_tags = []\n",
    "    unique_tags = set()\n",
    "    \n",
    "    print(f\"Processing {len(input_files)} files...\")\n",
    "    for input_file in input_files:\n",
    "        if not os.path.exists(input_file):\n",
    "            print(f\"Warning: File {input_file} not found.\")\n",
    "            continue\n",
    "        try:\n",
    "            with open(input_file, 'r', encoding='utf-8') as f:\n",
    "                obj = json.load(f)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error: Invalid JSON in {input_file}\")\n",
    "            continue\n",
    "        processed_content = obj.get('processed_content', [])\n",
    "        if not processed_content:\n",
    "            print(f\"No processed_content in {input_file}\")\n",
    "            continue\n",
    "        for sentence_idx, sentence_data in enumerate(processed_content):\n",
    "            tokens = sentence_data.get('tokens', [])\n",
    "            bio_tags = sentence_data.get('bio_tags', [])\n",
    "            if not tokens or not bio_tags:\n",
    "                print(f\"Warning: Empty tokens or bio_tags in {input_file}, sentence {sentence_idx}\")\n",
    "                continue\n",
    "            flattened_tags = [tags if isinstance(tags, str) else tags[0] if tags else \"O\" for tags in bio_tags]\n",
    "            if len(tokens) != len(flattened_tags):\n",
    "                print(f\"Warning: Mismatch in {input_file}, sentence {sentence_idx}: \"\n",
    "                      f\"{len(tokens)} tokens, {len(flattened_tags)} tags\")\n",
    "                continue\n",
    "            all_tokens.append(tokens)\n",
    "            all_tags.append(flattened_tags)\n",
    "            unique_tags.update(flattened_tags)\n",
    "    \n",
    "    print(f\"Loaded {len(all_tokens)} sentences\")\n",
    "    print(f\"Unique BIO tags: {sorted(unique_tags)}\")\n",
    "    if not all_tokens:\n",
    "        raise ValueError(\"No valid data loaded. Check file names, JSON structure, or data content.\")\n",
    "    return all_tokens, all_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1d7f50",
   "metadata": {},
   "source": [
    "# Define path and Output Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9c22cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input directory exists: True\n",
      "Files in directory: ['object_d2279a49-8b25-4e4c-b936-62f88487a895.json', 'object_e1a96cb5-7830-4846-a601-0a0357497b28.json', 'object_792495e7-39e6-4902-90b7-5edecd04877b.json', 'object_1fe657cc-df5b-4309-aaf2-e25e485b8ff4.json', 'object_04d28d27-96e9-4d95-b946-c1475b2207d2.json']\n",
      "Found 525 files: ['/home/guest/Public/KHEED/KHEED_Data_Collection/Final/bio_tagged/object_014f8a42-78bf-4e17-970b-c74bbb61a812.json', '/home/guest/Public/KHEED/KHEED_Data_Collection/Final/bio_tagged/object_017d1530-4fa2-4a7a-a1cb-0621640d579d.json', '/home/guest/Public/KHEED/KHEED_Data_Collection/Final/bio_tagged/object_01c58b61-821c-43e0-a7c6-8a858837fb0f.json', '/home/guest/Public/KHEED/KHEED_Data_Collection/Final/bio_tagged/object_0269da05-9c7b-447c-84c8-e3060217538d.json', '/home/guest/Public/KHEED/KHEED_Data_Collection/Final/bio_tagged/object_0274d277-8a68-4dae-8911-89da4097ba9c.json']\n",
      "Updated /home/guest/Public/KHEED/KHEED_Data_Collection/Evaluation/prahokbart_ner_model/input_files.json with 525 files\n"
     ]
    }
   ],
   "source": [
    "# Define paths for Ubuntu\n",
    "input_dir = \"/home/guest/Public/KHEED/KHEED_Data_Collection/Final/bio_tagged\"\n",
    "output_dir = \"/home/guest/Public/KHEED/KHEED_Data_Collection/Evaluation/prahokbart_ner_model\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Verify input directory\n",
    "print(f\"Input directory exists: {os.path.exists(input_dir)}\")\n",
    "print(f\"Files in directory: {os.listdir(input_dir)[:5]}\")\n",
    "\n",
    "# Load input files\n",
    "input_files = sorted(glob.glob(os.path.join(input_dir, \"object_*.json\")))\n",
    "if not input_files:\n",
    "    raise FileNotFoundError(f\"No files matching 'object_*.json' found in {input_dir}\")\n",
    "print(f\"Found {len(input_files)} files: {input_files[:5]}\")\n",
    "\n",
    "# Save input_files to JSON\n",
    "input_files_path = os.path.join(output_dir, \"input_files.json\")\n",
    "try:\n",
    "    with open(input_files_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(input_files, f)\n",
    "    print(f\"Updated {input_files_path} with {len(input_files)} files\")\n",
    "except PermissionError:\n",
    "    raise PermissionError(f\"Cannot write to {input_files_path}. Check permissions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164dc23a",
   "metadata": {},
   "source": [
    "# Load Tag Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "596d76f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 17 tags: ['B-Date', 'B-Disease', 'B-HumanCount', 'B-Location', 'B-Medication', 'B-Organization', 'B-Pathogen', 'B-Symptom', 'I-Date', 'I-Disease', 'I-HumanCount', 'I-Location', 'I-Medication', 'I-Organization', 'I-Pathogen', 'I-Symptom', 'O']\n"
     ]
    }
   ],
   "source": [
    "# Load tag2idx\n",
    "tag2idx_path = os.path.join(output_dir, \"tag2idx.json\")\n",
    "if not os.path.exists(tag2idx_path):\n",
    "    raise FileNotFoundError(f\"Missing tag2idx.json in {output_dir}\")\n",
    "try:\n",
    "    with open(tag2idx_path, 'r', encoding='utf-8') as f:\n",
    "        tag2idx = json.load(f)\n",
    "except PermissionError:\n",
    "    raise PermissionError(f\"Cannot read {tag2idx_path}. Check permissions.\")\n",
    "\n",
    "idx2tag = {int(idx): tag for tag, idx in tag2idx.items()}\n",
    "print(f\"Loaded {len(tag2idx)} tags: {list(tag2idx.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b11f78",
   "metadata": {},
   "source": [
    "# Load and Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "232f0efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 525 files...\n",
      "Warning: Empty tokens or bio_tags in /home/guest/Public/KHEED/KHEED_Data_Collection/Final/bio_tagged/object_1fba7077-406a-4006-b714-15ab19735e4a.json, sentence 16\n",
      "Warning: Empty tokens or bio_tags in /home/guest/Public/KHEED/KHEED_Data_Collection/Final/bio_tagged/object_22e414e8-ce76-4fb8-b40d-fb8c9ddcda0a.json, sentence 10\n",
      "Warning: Empty tokens or bio_tags in /home/guest/Public/KHEED/KHEED_Data_Collection/Final/bio_tagged/object_36df60cd-1185-4a6a-a7f7-ff79e1c46736.json, sentence 2\n",
      "Warning: Empty tokens or bio_tags in /home/guest/Public/KHEED/KHEED_Data_Collection/Final/bio_tagged/object_461f43b0-050e-424d-9395-6035d54214e0.json, sentence 6\n",
      "Warning: Empty tokens or bio_tags in /home/guest/Public/KHEED/KHEED_Data_Collection/Final/bio_tagged/object_5bc64b2c-dc8b-4f2a-be84-0ab5d5a9aa9d.json, sentence 29\n",
      "Warning: Empty tokens or bio_tags in /home/guest/Public/KHEED/KHEED_Data_Collection/Final/bio_tagged/object_7ee3a927-5a99-413a-a7df-b97efd7c6c25.json, sentence 21\n",
      "Warning: Empty tokens or bio_tags in /home/guest/Public/KHEED/KHEED_Data_Collection/Final/bio_tagged/object_99460ff0-1f7d-4ba9-bdf3-f6bcddb301a6.json, sentence 13\n",
      "Warning: Empty tokens or bio_tags in /home/guest/Public/KHEED/KHEED_Data_Collection/Final/bio_tagged/object_9af9ea0b-22ff-414d-aca0-f77b6b6e3886.json, sentence 9\n",
      "Warning: Empty tokens or bio_tags in /home/guest/Public/KHEED/KHEED_Data_Collection/Final/bio_tagged/object_a65da9e1-0627-4711-90cf-521b40ea5f05.json, sentence 11\n",
      "Warning: Empty tokens or bio_tags in /home/guest/Public/KHEED/KHEED_Data_Collection/Final/bio_tagged/object_b918108b-e414-4073-9b2c-559db2b17e10.json, sentence 16\n",
      "Warning: Empty tokens or bio_tags in /home/guest/Public/KHEED/KHEED_Data_Collection/Final/bio_tagged/object_c77280ad-7a35-4fdf-8f64-2004efcd9246.json, sentence 24\n",
      "Warning: Empty tokens or bio_tags in /home/guest/Public/KHEED/KHEED_Data_Collection/Final/bio_tagged/object_e1a96cb5-7830-4846-a601-0a0357497b28.json, sentence 31\n",
      "Loaded 6221 sentences\n",
      "Unique BIO tags: ['B-Date', 'B-Disease', 'B-HumanCount', 'B-Location', 'B-Medication', 'B-Organization', 'B-Pathogen', 'B-Symptom', 'I-Date', 'I-Disease', 'I-HumanCount', 'I-Location', 'I-Medication', 'I-Organization', 'I-Pathogen', 'I-Symptom', 'O']\n",
      "Train: 4976, Val: 622, Test: 623\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "all_tokens, all_tags = load_json_files(input_dir, input_files)\n",
    "if not all_tokens:\n",
    "    raise ValueError(\"No data loaded. Check input files or directory.\")\n",
    "\n",
    "# Verify tag2idx\n",
    "unique_tags = set(tag for tags in all_tags for tag in tags)\n",
    "missing_tags = unique_tags - set(tag2idx.keys())\n",
    "if missing_tags:\n",
    "    print(f\"Warning: Tags in data not in tag2idx: {missing_tags}\")\n",
    "    tag2idx = {tag: idx for idx, tag in enumerate(sorted(unique_tags))}\n",
    "    try:\n",
    "        with open(tag2idx_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(tag2idx, f)\n",
    "        print(f\"Updated {tag2idx_path} with {len(tag2idx)} tags\")\n",
    "    except PermissionError:\n",
    "        raise PermissionError(f\"Cannot write to {tag2idx_path}. Check permissions.\")\n",
    "\n",
    "# Split data\n",
    "train_tokens, temp_tokens, train_tags, temp_tags = train_test_split(\n",
    "        all_tokens, all_tags, test_size=0.2, random_state=42, stratify=None\n",
    "    )\n",
    "    \n",
    "val_tokens, test_tokens, val_tags, test_tags = train_test_split(\n",
    "    temp_tokens, temp_tags, test_size=0.5, random_state=42, stratify=None\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(train_tokens)}, Val: {len(val_tokens)}, Test: {len(test_tokens)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c23a1a",
   "metadata": {},
   "source": [
    "# Define Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db1e52e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrahokBARTNERDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tokens, tags, word2idx, tag2idx, max_len=128):\n",
    "        self.tokens = tokens\n",
    "        self.tags = tags\n",
    "        self.word2idx = word2idx  # Custom word2idx dictionary\n",
    "        self.tag2idx = tag2idx\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokens)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tokens = self.tokens[idx]\n",
    "        tags = self.tags[idx]\n",
    "\n",
    "        # Tokenize with khmernltk\n",
    "        if isinstance(tokens, str):\n",
    "            khmer_tokens = word_tokenize(tokens)\n",
    "        else:\n",
    "            khmer_tokens = tokens  # Assume pre-tokenized\n",
    "\n",
    "        # Convert tokens to input IDs using word2idx\n",
    "        input_ids = []\n",
    "        for token in khmer_tokens:\n",
    "            # Use word2idx ID or <unk> (ID 3) if token not found\n",
    "            input_ids.append(self.word2idx.get(token, self.word2idx.get('<unk>', 3)))\n",
    "\n",
    "        # Truncate or pad to max_len\n",
    "        if len(input_ids) > self.max_len:\n",
    "            input_ids = input_ids[:self.max_len]\n",
    "            aligned_tags = tags[:self.max_len]\n",
    "        else:\n",
    "            input_ids += [self.word2idx.get('<pad>', 1)] * (self.max_len - len(input_ids))\n",
    "            aligned_tags = tags + ['O'] * (self.max_len - len(tags)) if len(tags) < self.max_len else tags[:self.max_len]\n",
    "\n",
    "        # Create attention mask\n",
    "        attention_mask = [1 if idx != self.word2idx.get('<pad>', 1) else 0 for idx in input_ids]\n",
    "\n",
    "        # Align tags with tokens\n",
    "        labels = [-100] * self.max_len\n",
    "        for i in range(min(len(khmer_tokens), self.max_len)):\n",
    "            if i < len(aligned_tags):\n",
    "                labels[i] = self.tag2idx.get(aligned_tags[i], self.tag2idx.get('O', 0))\n",
    "\n",
    "        return {\n",
    "            'input_ids': torch.tensor(input_ids, dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(attention_mask, dtype=torch.long),\n",
    "            'labels': torch.tensor(labels, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f82169f",
   "metadata": {},
   "source": [
    "# Define Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32e1e0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrahokBARTForNER(torch.nn.Module):\n",
    "    def __init__(self, model_name, num_labels):\n",
    "        super().__init__()\n",
    "        self.mbart = MBartModel.from_pretrained(model_name)\n",
    "        self.dropout = torch.nn.Dropout(0.1)\n",
    "        self.classifier = torch.nn.Linear(self.mbart.config.d_model, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.mbart(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        sequence_output = outputs[0]\n",
    "        sequence_output = self.dropout(sequence_output)\n",
    "        logits = self.classifier(sequence_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = torch.nn.CrossEntropyLoss(ignore_index=-100)\n",
    "            loss = loss_fct(logits.view(-1, logits.size(-1)), labels.view(-1))\n",
    "\n",
    "        return loss, logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84d4462",
   "metadata": {},
   "source": [
    "# Initialize Tokenizer, Dataset, Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2452474c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded word2idx with 9705 tokens\n",
      "Data loaders created: 1244 train batches, 156 val batches, 156 test batches\n"
     ]
    }
   ],
   "source": [
    "# Initialize word2idx\n",
    "word2idx_path = os.path.join(output_dir, \"word2idx.json\")\n",
    "if not os.path.exists(word2idx_path):\n",
    "    raise FileNotFoundError(f\"Missing word2idx.json in {output_dir}\")\n",
    "try:\n",
    "    with open(word2idx_path, 'r', encoding='utf-8') as f:\n",
    "        word2idx = json.load(f)\n",
    "except Exception as e:\n",
    "    raise Exception(f\"Failed to load word2idx from {word2idx_path}: {str(e)}\")\n",
    "print(f\"Loaded word2idx with {len(word2idx)} tokens\")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = PrahokBARTNERDataset(train_tokens, train_tags, word2idx, tag2idx)\n",
    "val_dataset = PrahokBARTNERDataset(val_tokens, val_tags, word2idx, tag2idx)\n",
    "test_dataset = PrahokBARTNERDataset(test_tokens, test_tags, word2idx, tag2idx)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 4\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=custom_collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=custom_collate_fn)\n",
    "\n",
    "print(f\"Data loaders created: {len(train_loader)} train batches, {len(val_loader)} val batches, {len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49aacc0",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "deb35d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 [Train]:   0%|          | 0/1244 [00:00<?, ?it/s]Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.58.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "Epoch 1/20 [Train]: 100%|██████████| 1244/1244 [00:26<00:00, 47.68it/s, batch_loss=1.33]  \n",
      "Epoch 1/20 [Val]: 100%|██████████| 156/156 [00:00<00:00, 232.93it/s, batch_loss=0.546]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Train Loss: 0.7207, Val Loss: 0.4989\n",
      "Saved best model at epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 [Train]: 100%|██████████| 1244/1244 [00:26<00:00, 47.84it/s, batch_loss=0.309] \n",
      "Epoch 2/20 [Val]: 100%|██████████| 156/156 [00:00<00:00, 235.58it/s, batch_loss=0.45]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20, Train Loss: 0.4680, Val Loss: 0.3723\n",
      "Saved best model at epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 [Train]: 100%|██████████| 1244/1244 [00:26<00:00, 47.83it/s, batch_loss=0.444] \n",
      "Epoch 3/20 [Val]: 100%|██████████| 156/156 [00:00<00:00, 236.00it/s, batch_loss=0.324]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20, Train Loss: 0.3683, Val Loss: 0.3043\n",
      "Saved best model at epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 [Train]: 100%|██████████| 1244/1244 [00:26<00:00, 47.85it/s, batch_loss=0.164] \n",
      "Epoch 4/20 [Val]: 100%|██████████| 156/156 [00:00<00:00, 234.87it/s, batch_loss=0.25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20, Train Loss: 0.3032, Val Loss: 0.2561\n",
      "Saved best model at epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 [Train]: 100%|██████████| 1244/1244 [00:26<00:00, 47.78it/s, batch_loss=0.274]  \n",
      "Epoch 5/20 [Val]: 100%|██████████| 156/156 [00:00<00:00, 235.61it/s, batch_loss=0.204]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20, Train Loss: 0.2492, Val Loss: 0.2311\n",
      "Saved best model at epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 [Train]: 100%|██████████| 1244/1244 [00:26<00:00, 47.15it/s, batch_loss=0.156]  \n",
      "Epoch 6/20 [Val]: 100%|██████████| 156/156 [00:00<00:00, 235.00it/s, batch_loss=0.163]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20, Train Loss: 0.2189, Val Loss: 0.2213\n",
      "Saved best model at epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 [Train]: 100%|██████████| 1244/1244 [00:26<00:00, 47.78it/s, batch_loss=0.441]  \n",
      "Epoch 7/20 [Val]: 100%|██████████| 156/156 [00:00<00:00, 234.76it/s, batch_loss=0.174]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20, Train Loss: 0.1950, Val Loss: 0.2059\n",
      "Saved best model at epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 [Train]: 100%|██████████| 1244/1244 [00:26<00:00, 47.58it/s, batch_loss=0.0695] \n",
      "Epoch 8/20 [Val]: 100%|██████████| 156/156 [00:00<00:00, 234.65it/s, batch_loss=0.148]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20, Train Loss: 0.1757, Val Loss: 0.1967\n",
      "Saved best model at epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 [Train]: 100%|██████████| 1244/1244 [00:26<00:00, 47.44it/s, batch_loss=0.468]  \n",
      "Epoch 9/20 [Val]: 100%|██████████| 156/156 [00:00<00:00, 233.71it/s, batch_loss=0.151]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20, Train Loss: 0.1561, Val Loss: 0.1937\n",
      "Saved best model at epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 [Train]: 100%|██████████| 1244/1244 [00:26<00:00, 47.18it/s, batch_loss=0.121]  \n",
      "Epoch 10/20 [Val]: 100%|██████████| 156/156 [00:00<00:00, 231.14it/s, batch_loss=0.134]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20, Train Loss: 0.1445, Val Loss: 0.1871\n",
      "Saved best model at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 [Train]: 100%|██████████| 1244/1244 [00:26<00:00, 47.62it/s, batch_loss=0.0263] \n",
      "Epoch 11/20 [Val]: 100%|██████████| 156/156 [00:00<00:00, 234.87it/s, batch_loss=0.142]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20, Train Loss: 0.1308, Val Loss: 0.1901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 [Train]: 100%|██████████| 1244/1244 [00:26<00:00, 47.61it/s, batch_loss=0.212]  \n",
      "Epoch 12/20 [Val]: 100%|██████████| 156/156 [00:00<00:00, 235.43it/s, batch_loss=0.154]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20, Train Loss: 0.1207, Val Loss: 0.1785\n",
      "Saved best model at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 [Train]: 100%|██████████| 1244/1244 [00:26<00:00, 47.58it/s, batch_loss=0.0498]  \n",
      "Epoch 13/20 [Val]: 100%|██████████| 156/156 [00:00<00:00, 235.06it/s, batch_loss=0.145]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20, Train Loss: 0.1129, Val Loss: 0.1801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 [Train]: 100%|██████████| 1244/1244 [00:26<00:00, 47.55it/s, batch_loss=0.107]  \n",
      "Epoch 14/20 [Val]: 100%|██████████| 156/156 [00:00<00:00, 233.60it/s, batch_loss=0.163]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20, Train Loss: 0.1029, Val Loss: 0.1827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 [Train]: 100%|██████████| 1244/1244 [00:26<00:00, 47.57it/s, batch_loss=0.141]  \n",
      "Epoch 15/20 [Val]: 100%|██████████| 156/156 [00:00<00:00, 231.07it/s, batch_loss=0.167]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20, Train Loss: 0.0941, Val Loss: 0.1838\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = \"nict-astrec-att/prahokbart_base\"\n",
    "\n",
    "# Initialize model and optimizer\n",
    "model = PrahokBARTForNER(model_name, num_labels=len(tag2idx)).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Early stopping parameters\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "patience = 3\n",
    "num_epochs = 20\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    train_progress = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\", mininterval=1, leave=True)\n",
    "    for batch_idx, batch in enumerate(train_progress):\n",
    "        try:\n",
    "            # Debug: Print batch info\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss, _ = model(input_ids, attention_mask, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            train_progress.set_postfix({'batch_loss': loss.item()})\n",
    "            \n",
    "        \n",
    "        except RuntimeError as e:\n",
    "            print(f\"Error in batch {batch_idx+1}: {str(e)}\")\n",
    "            if \"CUDA out of memory\" in str(e):\n",
    "                print(\"CUDA out of memory. Try reducing batch_size or max_len.\")\n",
    "                torch.cuda.empty_cache()\n",
    "                raise\n",
    "            raise\n",
    "        \n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    \n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    val_progress = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\", mininterval=1, leave=True)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(val_progress):\n",
    "            try:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "                \n",
    "                loss, _ = model(input_ids, attention_mask, labels)\n",
    "                total_val_loss += loss.item()\n",
    "                val_progress.set_postfix({'batch_loss': loss.item()})\n",
    "            \n",
    "            except RuntimeError as e:\n",
    "                print(f\"Error in validation batch {batch_idx+1}: {str(e)}\")\n",
    "                if \"CUDA out of memory\" in str(e):\n",
    "                    print(\"CUDA out of memory in validation. Try reducing batch_size.\")\n",
    "                    torch.cuda.empty_cache()\n",
    "                    raise\n",
    "                raise\n",
    "    \n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        try:\n",
    "            torch.save(model.state_dict(), os.path.join(output_dir, \"prahokbart_ner.pt\"))\n",
    "            print(f\"Saved best model at epoch {epoch+1}\")\n",
    "        except PermissionError:\n",
    "            raise PermissionError(f\"Cannot write to {os.path.join(output_dir, 'prahokbart_ner.pt')}. Check permissions.\")\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    \n",
    "    if patience_counter >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch+1}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54f0bdd",
   "metadata": {},
   "source": [
    "# Evaluate and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16fe4899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded best model for evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Test Set: 100%|██████████| 156/156 [00:00<00:00, 200.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to /home/guest/Public/KHEED/KHEED_Data_Collection/Evaluation/prahokbart_ner_model/predictions.json\n",
      "Saved predictions to /home/guest/Public/KHEED/KHEED_Data_Collection/Evaluation/prahokbart_ner_model/predictions.conll\n",
      "\n",
      "Evaluation Metrics:\n",
      "    Category  Precision  Recall  F1-Score  Support\n",
      "        Date     0.6458  0.6458    0.6458      144\n",
      "     Disease     0.6834  0.8163    0.7440      283\n",
      "  HumanCount     0.4865  0.4932    0.4898       73\n",
      "    Location     0.6317  0.6934    0.6611      287\n",
      "  Medication     0.0968  0.1500    0.1176       20\n",
      "Organization     0.4301  0.5845    0.4955      284\n",
      "    Pathogen     0.7955  0.7609    0.7778       46\n",
      "     Symptom     0.5833  0.5185    0.5490       54\n",
      "   Micro Avg     0.5732  0.6641    0.6153     1191\n",
      "   Macro Avg     0.5441  0.5828    0.5601     1191\n",
      "Weighted Avg     0.5839  0.6641    0.6193     1191\n",
      "\n",
      "Overall Metrics:\n",
      "Precision: 0.5732\n",
      "Recall: 0.6641\n",
      "F1-Score: 0.6153\n",
      "Saved evaluation metrics to /home/guest/Public/KHEED/KHEED_Data_Collection/Evaluation/prahokbart_ner_model/evaluation_metrics.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame for tabular formatting\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from seqeval.metrics import classification_report, precision_score, recall_score, f1_score\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load best model\n",
    "try:\n",
    "    model.load_state_dict(torch.load(os.path.join(output_dir, \"prahokbart_ner.pt\"), map_location=device))\n",
    "    print(\"Loaded best model for evaluation\")\n",
    "except PermissionError:\n",
    "    raise PermissionError(f\"Cannot read {os.path.join(output_dir, 'prahokbart_ner.pt')}. Check permissions.\")\n",
    "\n",
    "# Evaluate on test set\n",
    "model.eval()\n",
    "all_true_tags = []\n",
    "all_pred_tags = []\n",
    "all_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Evaluating Test Set\"):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels']\n",
    "        \n",
    "        _, logits = model(input_ids, attention_mask)\n",
    "        pred_tag_ids = torch.argmax(logits, dim=-1)\n",
    "        \n",
    "        for pred_ids, true_ids in zip(pred_tag_ids, labels):\n",
    "            true_tags = []\n",
    "            for idx in true_ids:\n",
    "                idx_val = idx.item()\n",
    "                if idx_val != -100 and 0 <= idx_val < len(idx2tag):\n",
    "                    true_tags.append(idx2tag[idx_val])\n",
    "            \n",
    "            pred_tags = []\n",
    "            for idx in pred_ids[:len(true_tags)]:\n",
    "                idx_val = idx.item()\n",
    "                if 0 <= idx_val < len(idx2tag):\n",
    "                    pred_tags.append(idx2tag[idx_val])\n",
    "                else:\n",
    "                    pred_tags.append('O')  # fallback to 'O' if out of range\n",
    "            \n",
    "            all_true_tags.append(true_tags)\n",
    "            all_pred_tags.append(pred_tags)\n",
    "            all_predictions.append({\n",
    "                'tokens': [],\n",
    "                'true_tags': true_tags,\n",
    "                'pred_tags': pred_tags\n",
    "            })\n",
    "\n",
    "# Save predictions to JSON\n",
    "json_path = os.path.join(output_dir, \"predictions.json\")\n",
    "try:\n",
    "    with open(json_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(all_predictions, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"Saved predictions to {json_path}\")\n",
    "except PermissionError:\n",
    "    raise PermissionError(f\"Cannot write to {json_path}. Check permissions.\")\n",
    "\n",
    "# Save predictions to CoNLL format\n",
    "conll_path = os.path.join(output_dir, \"predictions.conll\")\n",
    "try:\n",
    "    with open(conll_path, 'w', encoding='utf-8') as f:\n",
    "        for pred in all_predictions:\n",
    "            for true_tag, pred_tag in zip(pred['true_tags'], pred['pred_tags']):\n",
    "                f.write(f\"_\\t{true_tag}\\t{pred_tag}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "    print(f\"Saved predictions to {conll_path}\")\n",
    "except PermissionError:\n",
    "    raise PermissionError(f\"Cannot write to {conll_path}. Check permissions.\")\n",
    "\n",
    "# Custom function to compute NER metrics\n",
    "def compute_ner_metrics(true_tags_list, pred_tags_list):\n",
    "    # Extract unique categories (excluding 'O' and IOB2 prefixes)\n",
    "    categories = set()\n",
    "    for tags in true_tags_list + pred_tags_list:\n",
    "        for tag in tags:\n",
    "            if tag != 'O':\n",
    "                category = tag.split('-')[-1]  # Get category (e.g., 'Disease' from 'B-Disease')\n",
    "                categories.add(category)\n",
    "    categories = sorted(categories)\n",
    "\n",
    "    # Initialize counters\n",
    "    metrics = defaultdict(lambda: {'tp': 0, 'fp': 0, 'fn': 0, 'support': 0})\n",
    "\n",
    "    def extract_entities(tags):\n",
    "        entities = []\n",
    "        current_entity = None\n",
    "        for i, tag in enumerate(tags):\n",
    "            if tag == 'O':\n",
    "                if current_entity:\n",
    "                    entities.append((current_entity[0], current_entity[1], current_entity[2]))\n",
    "                    current_entity = None\n",
    "                continue\n",
    "            \n",
    "            if '-' in tag:\n",
    "                prefix, category = tag.split('-', 1)\n",
    "            else:\n",
    "                prefix, category = 'B', tag  # Assume B- if no prefix\n",
    "            \n",
    "            if prefix == 'B' or (prefix == 'I' and not current_entity):\n",
    "                if current_entity:\n",
    "                    entities.append((current_entity[0], current_entity[1], current_entity[2]))\n",
    "                current_entity = (category, i, i)\n",
    "            elif prefix == 'I' and current_entity and current_entity[0] == category:\n",
    "                current_entity = (current_entity[0], current_entity[1], i)\n",
    "            else:\n",
    "                if current_entity:\n",
    "                    entities.append((current_entity[0], current_entity[1], current_entity[2]))\n",
    "                    current_entity = None\n",
    "                if prefix == 'B':\n",
    "                    current_entity = (category, i, i)\n",
    "        \n",
    "        if current_entity:\n",
    "            entities.append((current_entity[0], current_entity[1], current_entity[2]))\n",
    "        return entities\n",
    "\n",
    "    # Process each sequence\n",
    "    for true_tags, pred_tags in zip(true_tags_list, pred_tags_list):\n",
    "        true_entities = extract_entities(true_tags)\n",
    "        pred_entities = extract_entities(pred_tags)\n",
    "\n",
    "        # Group entities by category\n",
    "        true_by_category = defaultdict(set)\n",
    "        pred_by_category = defaultdict(set)\n",
    "        \n",
    "        for category, start, end in true_entities:\n",
    "            true_by_category[category].add((start, end))\n",
    "        \n",
    "        for category, start, end in pred_entities:\n",
    "            pred_by_category[category].add((start, end))\n",
    "\n",
    "        # Calculate metrics for each category\n",
    "        for category in categories:\n",
    "            true_cat_entities = true_by_category[category]\n",
    "            pred_cat_entities = pred_by_category[category]\n",
    "\n",
    "            metrics[category]['support'] += len(true_cat_entities)\n",
    "            metrics[category]['tp'] += len(true_cat_entities & pred_cat_entities)\n",
    "            metrics[category]['fp'] += len(pred_cat_entities - true_cat_entities)\n",
    "            metrics[category]['fn'] += len(true_cat_entities - pred_cat_entities)\n",
    "\n",
    "    # Compute precision, recall, F1-score\n",
    "    results = {}\n",
    "    total_tp, total_fp, total_fn, total_support = 0, 0, 0, 0\n",
    "    \n",
    "    for category in categories:\n",
    "        tp = metrics[category]['tp']\n",
    "        fp = metrics[category]['fp']\n",
    "        fn = metrics[category]['fn']\n",
    "        support = metrics[category]['support']\n",
    "        \n",
    "        total_tp += tp\n",
    "        total_fp += fp\n",
    "        total_fn += fn\n",
    "        total_support += support\n",
    "\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "\n",
    "        results[category] = {\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1-score': f1,\n",
    "            'support': support\n",
    "        }\n",
    "\n",
    "    # Compute micro, macro, weighted averages\n",
    "    micro_precision = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0.0\n",
    "    micro_recall = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0.0\n",
    "    micro_f1 = 2 * (micro_precision * micro_recall) / (micro_precision + micro_recall) if (micro_precision + micro_recall) > 0 else 0.0\n",
    "\n",
    "    macro_precision = np.mean([results[cat]['precision'] for cat in categories]) if categories else 0.0\n",
    "    macro_recall = np.mean([results[cat]['recall'] for cat in categories]) if categories else 0.0\n",
    "    macro_f1 = np.mean([results[cat]['f1-score'] for cat in categories]) if categories else 0.0\n",
    "\n",
    "    weighted_precision = sum(results[cat]['precision'] * results[cat]['support'] for cat in categories) / total_support if total_support > 0 else 0.0\n",
    "    weighted_recall = sum(results[cat]['recall'] * results[cat]['support'] for cat in categories) / total_support if total_support > 0 else 0.0\n",
    "    weighted_f1 = sum(results[cat]['f1-score'] * results[cat]['support'] for cat in categories) / total_support if total_support > 0 else 0.0\n",
    "\n",
    "    results['micro avg'] = {'precision': micro_precision, 'recall': micro_recall, 'f1-score': micro_f1, 'support': total_support}\n",
    "    results['macro avg'] = {'precision': macro_precision, 'recall': macro_recall, 'f1-score': macro_f1, 'support': total_support}\n",
    "    results['weighted avg'] = {'precision': weighted_precision, 'recall': weighted_recall, 'f1-score': weighted_f1, 'support': total_support}\n",
    "\n",
    "    return results, micro_precision, micro_recall, micro_f1\n",
    "\n",
    "# Compute metrics\n",
    "report_dict, overall_precision, overall_recall, overall_f1 = compute_ner_metrics(all_true_tags, all_pred_tags)\n",
    "\n",
    "# Create DataFrame for display\n",
    "categories = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "supports = []\n",
    "\n",
    "# Add individual categories\n",
    "for label, scores in report_dict.items():\n",
    "    if label not in ['micro avg', 'macro avg', 'weighted avg']:\n",
    "        categories.append(label)\n",
    "        precisions.append(scores['precision'])\n",
    "        recalls.append(scores['recall'])\n",
    "        f1_scores.append(scores['f1-score'])\n",
    "        supports.append(scores['support'])\n",
    "\n",
    "# Add averages\n",
    "for avg_type in ['micro avg', 'macro avg', 'weighted avg']:\n",
    "    if avg_type in report_dict:\n",
    "        categories.append(avg_type.title())\n",
    "        precisions.append(report_dict[avg_type]['precision'])\n",
    "        recalls.append(report_dict[avg_type]['recall'])\n",
    "        f1_scores.append(report_dict[avg_type]['f1-score'])\n",
    "        supports.append(report_dict[avg_type]['support'])\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Category': categories,\n",
    "    'Precision': precisions,\n",
    "    'Recall': recalls,\n",
    "    'F1-Score': f1_scores,\n",
    "    'Support': supports\n",
    "})\n",
    "\n",
    "# Format numbers to two decimal places\n",
    "df['Precision'] = df['Precision'].round(4)\n",
    "df['Recall'] = df['Recall'].round(4)\n",
    "df['F1-Score'] = df['F1-Score'].round(4)\n",
    "df['Support'] = df['Support'].astype(int)\n",
    "\n",
    "# Print formatted table\n",
    "print(\"\\nEvaluation Metrics:\")\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# Print overall metrics\n",
    "print(\"\\nOverall Metrics:\")\n",
    "print(f\"Precision: {overall_precision:.4f}\")\n",
    "print(f\"Recall: {overall_recall:.4f}\")\n",
    "print(f\"F1-Score: {overall_f1:.4f}\")\n",
    "\n",
    "# Save metrics to file\n",
    "metrics_path = os.path.join(output_dir, \"evaluation_metrics.json\")\n",
    "try:\n",
    "    with open(metrics_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(report_dict, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"Saved evaluation metrics to {metrics_path}\")\n",
    "except PermissionError:\n",
    "    raise PermissionError(f\"Cannot write to {metrics_path}. Check permissions.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kheed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
